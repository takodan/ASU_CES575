# Set-up of the unsupervised learning problem
1. 無標籤數據
    1. 估計數據分布
    2. (如果有)找出分組
    3. 確定特徵
2. 混合密度模型
    1. 假設
        1. 有C類
        2. 每個類別的先驗概率已知
        3. 

# The k-means Algorithm
1. cluster簇
    1. 質心: 簇的中心
    2. 利用和質心的相似性來分組
    3. 相似性可以利用歐式距離(兩點間的距離)來做度量, 但是
    4. 也可以用其他方式做度量, 例如 cosine similarity余弦相似性(夾角角度)
2. 以歐式距離為例
    1. 平均做為質心
    2. 平方差來判斷質心
        1. 目標是最小化所有分區的平方差和
        2. 是NP Hard 問題
3. hard membership硬分配
    1. 樣本只能分到一類
    2. 軟分配則是表示分到某一類的機率
3. k均值聚類算法
    1. 不一定會找到全局最優解
    2. 基於到質心的距離作硬分配
    3. 算法
        1. 給定n個樣本, 分成k組
        2. 隨機選擇k個樣本作為質心u
        3. 根據到質心的距離分配樣本到不同組
        4. 重新計算每個組的平均作為質心
        5. 重複3, 4 直到重新計算的質心u沒有變化(收斂)
        6. 返回最後的質心u
# Analyzing the k-means Algorithm
1. k均值算法屬性
    1. 算法最後會收斂
    2. 結果不一定是最優解
    3. 初始質心會對結果有很大的影響
2. 改善k均值算法的技巧
    1. 選擇最遠的樣本作為質心
        1. 缺點: 對outlier異常值敏感
    2. 使用不同的質心多次進行k均值算法
        1. 再比較平方差選擇較好的結果
3. k均值算法變體
    1. k均值++
        1. 介於最遠和隨機之間的方法
    2. 分層方法
        1. 凝聚
        2. 分類
4. 選擇k
    1. 如果k=1, 誤差即為所有樣本的平方差
    2. 如果k=n, 每個樣本一類誤差為0
    3. 找尋技巧
        1. 代價函數在某個點急遽下降(這裡指的就是平方差)
        2. 交叉驗證: 例如下一步的任務結果是好的, 那這k值可能也是好的