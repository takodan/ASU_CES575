# Linear Machines(Linear Classifiers): Basic
1. 線性分類器
    1. 邏輯回歸中, 給定一個標籤樣本訓練集<x^i, y^i>, 假設一個S型函數學習P(y|x)
    2. 會得到線性分類器, 藉由(w^t)x=>0和(w^t)x<0來分類
    3. g(x)=(w^t)x稱為判別函數
    4. 邏輯回歸是一種線性分類器
2. 線性判別函數
    1. 學習目標是使用訓練樣本估計判別函數參數
    2. 使用線性判別函數產生判定邊界, 稱作線性分類器
    3. 判別函數寫作g(x)=(w^t)x或g(x)=(w^t)x+w_0
        - 差別在於第一段函數包含w_0和1, 擴展後是相等的
3. 多於兩類的線性分類器
    1. 判別函數寫作g_i(x)=(w_i^t)x, i=1, 2, ..., C
    2. 可以藉由g_i(x)>=g_j(x), j!=i來分類
4. 線性分類器的可分性
    1. 如果至少可以求出一個矢量w, 使得g(x)=(w^t)x能正確分類所有樣本
        - 線性可分的
    2. 可以以圖示判別
    3. 可能有多個矢量都是有效解, 這些矢量所在區間稱為解域
5. 求解權矢量
    1. 優化函數的同時也要滿足要求: 約束優化問題
    2. 理論方法: 拉格朗日乘數法, KKT條件
    3. 實際方法: 梯度下降法
6. 複習梯度下降法
    1. 定義代價函數J(w)
    2. 從初始權矢量w(0)開始
    3. 透過公式更新w

# The Concept of Margin
1. 法向量
    1. 利用一個點到判定面的距離訂為法向量
    2. 可以利用法向量和判定面表示任何一個點
        - 推導得到r = g(x)/(||w||)
2. margin間隔: 指樣本x到判定面的距離, 或是樣本集中到判定面的最小距離

# SVM: Linearly-separable Case
1. 支持矢量機
    1. 用於求出判定邊界, 使間隔最大化


    